{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iit2018146_q6c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUZpFS38MUGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNlL2EXcWlJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath='/Housing Price data set.csv'"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k86SUeeuq4Zi",
        "colab_type": "text"
      },
      "source": [
        "# **Storing the value**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cX2I62CWsvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price=[]\n",
        "area=[]\n",
        "bedroom=[]\n",
        "bathroom=[]\n",
        "count=0\n",
        "with open(filepath, mode ='r') as file:     \n",
        "   csvFile = csv.reader(file) \n",
        "   for lines in csvFile:\n",
        "     if count==0:\n",
        "       count=count+1\n",
        "       continue\n",
        "     price.append(int(float(lines[1])))\n",
        "     area.append(int(lines[2]))\n",
        "     bedroom.append(int(lines[3]))\n",
        "     bathroom.append(int(lines[4]))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSFl9zxnXzE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m= round(0.7*len(price))\n",
        "n=4\n",
        "X1=np.array(area)\n",
        "X2=np.array(bedroom)\n",
        "X3=np.array(bathroom)\n",
        "Y=np.array(price)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QmrtauVq-6Y",
        "colab_type": "text"
      },
      "source": [
        "# **Training data and Testing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDYauYUvaRVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train1=X1[:m]\n",
        "X_train2=X2[:m]\n",
        "X_train3=X3[:m]\n",
        "Y_train=Y[:m]\n",
        "\n",
        "X_test1=X1[m+1:]\n",
        "X_test2=X2[m+1:]\n",
        "X_test3=X3[m+1:]\n",
        "Y_test=Y[m+1:]\n",
        "\n",
        "X_train0=np.ones(m,dtype=int)\n",
        "X_test0=np.ones(len(X_test1),dtype=int)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WEPTVgqa5M_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=[]\n",
        "for i  in range(m):\n",
        "  col=[]\n",
        "  col.append(X_train0[i])\n",
        "  col.append(X_train1[i])\n",
        "  col.append(X_train2[i])\n",
        "  col.append(X_train3[i])\n",
        "  X_train.append(col)\n",
        "X_bar=np.array(X_train)\n",
        "X=np.array([X_train0,X_train1,X_train2,X_train3])\n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrdqXWVexFQF",
        "colab_type": "text"
      },
      "source": [
        "# **Batch Gradient Descent Algorithm Without Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2AmBiWHJoOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Batch_Gradient_descent_algo(X,Y_train):\n",
        "  iteration=1000\n",
        "  m=X[0].size\n",
        "  learning_rate=0.0000000001\n",
        "  theta=np.ones(len(X),dtype=int)\n",
        "  for i in range(iteration):\n",
        "    y_pre=np.dot(theta.T,X)\n",
        "    theta=theta-learning_rate*(1.0/m)*np.dot(y_pre-Y_train,X.T)\n",
        "\n",
        "  return theta"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNStzOvUxXkk",
        "colab_type": "text"
      },
      "source": [
        "# **Stochastic Gradient Descent Algorithm Without Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BCujDmdAXtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine(X,Y_train):\n",
        "  cc=[]\n",
        "  for i in range(len(X)):\n",
        "    col=[]\n",
        "    col.append(X[i][0])\n",
        "    col.append(X[i][1])\n",
        "    col.append(X[i][2])\n",
        "    col.append(X[i][3])\n",
        "    col.append(Y_train[i])\n",
        "    cc.append(col)\n",
        "  \n",
        "  cc=np.array(cc)\n",
        "  return cc\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ol62bkfNSdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_shuffle(matrix):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for i in range(len(matrix)):\n",
        "    col=[]\n",
        "    col.append(matrix[i][0])\n",
        "    col.append(matrix[i][1])\n",
        "    col.append(matrix[i][2])\n",
        "    col.append(matrix[i][3])\n",
        "    X.append(col)\n",
        "    Y.append(matrix[i][4])\n",
        "  X=np.array(X)\n",
        "  Y=np.array(Y)\n",
        "  return X,Y"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgL5jNP7zjua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Stochastic_Gradient_descent_algo(X,Y_train):\n",
        "  shuffle_matrix=combine(X,Y_train)\n",
        "  np.random.shuffle(shuffle_matrix)\n",
        "  X,Y_train=split_shuffle(shuffle_matrix)\n",
        "  m=len(X)\n",
        "  iteration=1000\n",
        "  learning_rate=0.0000000001\n",
        "  thetas=np.ones(X[0].size,dtype=float)\n",
        "\n",
        "  for it  in range(iteration):\n",
        "    for i in range(m):\n",
        "      predic= 1.0*(thetas[0]*X[i][0] + thetas[1]*X[i][1] + thetas[2]*X[i][2] +thetas[3]*X[i][3] - Y_train[i])\n",
        "\n",
        "      thata0=thetas[0]-1.0*learning_rate*(predic)*X[i][0]\n",
        "      thata1=thetas[1]-1.0*learning_rate*(predic)*X[i][1]\n",
        "      thata2=thetas[2]-1.0*learning_rate*(predic)*X[i][2]\n",
        "      thata3=thetas[3]-1.0*learning_rate*(predic)*X[i][3]\n",
        "\n",
        "      thetas[0]=thata0\n",
        "      thetas[1]=thata1\n",
        "      thetas[2]=thata2\n",
        "      thetas[3]=thata3\n",
        "  return thetas"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEaUIiN6xmfh",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracy Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QwGV0T3iLph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=[]\n",
        "for i  in range(len(X_test1)):\n",
        "  col=[]\n",
        "  col.append(X_test0[i])\n",
        "  col.append(X_test1[i])\n",
        "  col.append(X_test2[i])\n",
        "  col.append(X_test3[i])\n",
        "  X_test.append(col)\n",
        "X_test=np.array(X_test)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEnBzV-YhqUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def error(theta,Y_test,X_test):\n",
        "  Y_predic=X_test.dot(theta)   \n",
        "  error_diff=np.subtract(Y_test,Y_predic)\n",
        "  abserror_diff=np.absolute(error_diff)\n",
        "  absolute_error=np.divide(abserror_diff,Y_test)\n",
        "  mean_ab_error=np.mean(absolute_error)\n",
        "  return mean_ab_error*100"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD2nas5Ax0qY",
        "colab_type": "text"
      },
      "source": [
        "# **Mini Batch Gradient Descent Algorithm Without Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ukuJdgoEiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(X,y,batch_size,i):\n",
        "    X_batch = X[i:i+batch_size,:]\n",
        "    y_batch = y[i:i+batch_size]    \n",
        "    return X_batch, y_batch"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvE5CQOmpvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Mini_Batch_Gradient_descent_algo(X,Y_train):\n",
        "  batch_size=10\n",
        "  num_batches = int(X.shape[0]/batch_size) \n",
        "  theta=np.ones(X[0].size,dtype=float)\n",
        "  # print(num_batches)\n",
        "  alpha=0.000000001\n",
        "  for i in range(0,num_batches):\n",
        "    X_batch, y_batch = get_batches(X,Y_train,batch_size,i)\n",
        "    predic = np.dot(X_batch,theta)\n",
        "    theta = theta - alpha * np.dot(X_batch.T,predic - y_batch)/batch_size\n",
        "  \n",
        "  thet=[]\n",
        "  thet.append(theta[0])\n",
        "  thet.append(theta[1])\n",
        "  thet.append(theta[2])\n",
        "  thet.append(theta[3])\n",
        "  \n",
        "  thet=np.array(thet)\n",
        "  return thet"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-CzDiP6yCIS",
        "colab_type": "text"
      },
      "source": [
        "# **MAIN without Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp0WcHvAhS0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ebc37486-6103-4e0c-8ba9-b592098f86d7"
      },
      "source": [
        "print(\"               WITHOUT REGULARIZATION                  \")\n",
        "print(\" \")\n",
        "batch_theta=Batch_Gradient_descent_algo(X,Y_train)\n",
        "print(\"Theta Value for Batch Gradient descent Algorihtm Without Regularization\")\n",
        "print(batch_theta)\n",
        "print(\"\")\n",
        "error_batch_gda=error(batch_theta,Y_test,X_test)\n",
        "print(\"Accuracy Prediction for Batch Gradient descent Algorithm Without Regularization\")\n",
        "print(error_batch_gda)\n",
        "\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\" \")\n",
        "stochastic_theta=Stochastic_Gradient_descent_algo(X_bar,Y_train)\n",
        "print(\"Theta Value for Stochastic Gradient descent Algorihtm Without Regularization\")\n",
        "print(stochastic_theta)\n",
        "print(\" \")\n",
        "error_stochastic_gda=error(stochastic_theta,Y_test,X_test)\n",
        "print(\"Accuracy Prediction for Stochastic Gradient descent Algorithm Without Regularization\")\n",
        "print(error_stochastic_gda)\n",
        "\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\" \")\n",
        "mini_batch_theta=Mini_Batch_Gradient_descent_algo(X_bar,Y_train)\n",
        "print(\"Theta Value for Mini Batch Gradient descent Algorihtm Without Regularization\")\n",
        "print(mini_batch_theta)\n",
        "print(\" \")\n",
        "error_mini_batch=error(mini_batch_theta,Y_test,X_test)\n",
        "print(\"Accuracy Prediction for Mini Batch Gradient descent Algorithm Without Regularization\")\n",
        "print(error_mini_batch)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               WITHOUT REGULARIZATION                  \n",
            " \n",
            "Theta Value for Batch Gradient descent Algorihtm Without Regularization\n",
            "[ 1.0023332  11.72948415  1.00742127  1.00350479]\n",
            "\n",
            "Accuracy Prediction for Batch Gradient descent Algorithm Without Regularization\n",
            "30.229953002026335\n",
            "--------------------------------------------------------------\n",
            " \n",
            "Theta Value for Stochastic Gradient descent Algorihtm Without Regularization\n",
            "[ 1.16626562 12.37331381  1.65830149  1.37097262]\n",
            " \n",
            "Accuracy Prediction for Stochastic Gradient descent Algorithm Without Regularization\n",
            "29.956567369151966\n",
            "--------------------------------------------------------------\n",
            " \n",
            "Theta Value for Mini Batch Gradient descent Algorihtm Without Regularization\n",
            "[1.00133967 6.96105709 1.00368276 1.00170685]\n",
            " \n",
            "Accuracy Prediction for Mini Batch Gradient descent Algorithm Without Regularization\n",
            "47.159202904283795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR1l1NXrTQco",
        "colab_type": "text"
      },
      "source": [
        "# **Batch Gradient Descent Algorithm with Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izfCNLBTTPmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Batch_Gradient_descent_algo_regularization(X,Y_train):\n",
        "  iteration=1000\n",
        "  m=X[0].size\n",
        "  learning_rate=0.0000000001\n",
        "  lambd=50000000\n",
        "  theta=np.ones(len(X),dtype=int)\n",
        "  for i in range(iteration):\n",
        "    y_pre=np.dot(theta.T,X)\n",
        "    theta=theta-learning_rate*(1.0/m)*np.dot(y_pre-Y_train,X.T)- ((1.0*lambd*learning_rate)/m)*theta\n",
        "\n",
        "  return theta"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNsOPrk-YIwl",
        "colab_type": "text"
      },
      "source": [
        "# **Stochastic Gradient Descent Algorithm With Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FkNlOBjYDRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Stochastic_Gradient_descent_algo_regularization(X,Y_train):\n",
        "  shuffle_matrix=combine(X,Y_train)\n",
        "  np.random.shuffle(shuffle_matrix)\n",
        "  X,Y_train=split_shuffle(shuffle_matrix)\n",
        "  m=len(X)\n",
        "  iteration=1000\n",
        "  learning_rate=0.0000000001\n",
        "  lambd=50000000\n",
        "  thetas=np.ones(X[0].size,dtype=float)\n",
        "\n",
        "  for it  in range(iteration):\n",
        "    for i in range(m):\n",
        "      predic= 1.0*(thetas[0]*X[i][0] + thetas[1]*X[i][1] + thetas[2]*X[i][2] +thetas[3]*X[i][3] - Y_train[i])\n",
        "\n",
        "      thata0=thetas[0]-1.0*learning_rate*(predic)*X[i][0] \n",
        "      thata1=thetas[1]-1.0*learning_rate*(predic)*X[i][1] - thetas[1]*((1.0*learning_rate*lambd)/m)\n",
        "      thata2=thetas[2]-1.0*learning_rate*(predic)*X[i][2] - thetas[2]*((1.0*learning_rate*lambd)/m)\n",
        "      thata3=thetas[3]-1.0*learning_rate*(predic)*X[i][3] - thetas[3]*((1.0*learning_rate*lambd)/m)\n",
        "\n",
        "      thetas[0]=thata0\n",
        "      thetas[1]=thata1\n",
        "      thetas[2]=thata2\n",
        "      thetas[3]=thata3\n",
        "  return thetas"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzTXfpC6XZK2",
        "colab_type": "text"
      },
      "source": [
        "# **Mini Batch Gradient Descent Algorithm With Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CKoc9MbXYUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Mini_Batch_Gradient_descent_algo_regularization(X,Y_train):\n",
        "  batch_size=10\n",
        "  num_batches = int(X.shape[0]/batch_size) \n",
        "  theta=np.ones(X[0].size,dtype=float)\n",
        "  # print(num_batches)\n",
        "  alpha=0.000000001\n",
        "  lambd=5000000\n",
        "  for i in range(0,num_batches):\n",
        "    X_batch, y_batch = get_batches(X,Y_train,batch_size,i)\n",
        "    predic = np.dot(X_batch,theta)\n",
        "    theta = theta - alpha*(1.0/batch_size) * np.dot(X_batch.T,predic - y_batch) -((1.0*lambd*alpha)/batch_size)*theta\n",
        "  \n",
        "  thet=[]\n",
        "  thet.append(theta[0])\n",
        "  thet.append(theta[1])\n",
        "  thet.append(theta[2])\n",
        "  thet.append(theta[3])\n",
        "  \n",
        "  thet=np.array(thet)\n",
        "  return thet"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGDE1jeebmiG",
        "colab_type": "text"
      },
      "source": [
        "# **MAIN with Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M6MswcpbluN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a1ee8da6-d075-4060-d02c-74b2dc5ac697"
      },
      "source": [
        "print(\"                   WITH REGULARIZATION                     \")\n",
        "print(\" \")\n",
        "batch_theta_regulari=Batch_Gradient_descent_algo_regularization(X,Y_train)\n",
        "print(\"Theta Value for Batch Gradient descent Algorihtm With Regularization\")\n",
        "print(batch_theta_regulari)\n",
        "print(\"\")\n",
        "error_batch_gda_regulari=error(batch_theta_regulari,Y_test,X_test)\n",
        "print(\"Accuracy Prediction for Batch Gradient descent Algorithm With Regularization\")\n",
        "print(error_batch_gda_regulari)\n",
        "\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\" \")\n",
        "stochastic_theta_regulari=Stochastic_Gradient_descent_algo_regularization(X_bar,Y_train)\n",
        "print(\"Theta Value for Stochastic Gradient descent Algorihtm With Regularization\")\n",
        "print(stochastic_theta_regulari)\n",
        "print(\" \")\n",
        "error_stochastic_gda_regulari=error(stochastic_theta_regulari,Y_test,X_test)\n",
        "print(\"Accuracy Prediction for Stochastic Gradient descent Algorithm With Regularization\")\n",
        "print(error_stochastic_gda_regulari)\n",
        "\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\" \")\n",
        "mini_batch_theta_regulari=Mini_Batch_Gradient_descent_algo_regularization(X_bar,Y_train)\n",
        "print(\"Theta Value for Mini Batch Gradient descent Algorihtm With Regularization\")\n",
        "print(mini_batch_theta_regulari)\n",
        "print(\" \")\n",
        "error_mini_batch_regulari=error(mini_batch_theta_regulari,Y_test,X_test)\n",
        "print(\"Accuracy Prediction for Mini Batch Gradient descent Algorithm With Regularization\")\n",
        "print(error_mini_batch_regulari)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   WITH REGULARIZATION                     \n",
            " \n",
            "Theta Value for Batch Gradient descent Algorihtm With Regularization\n",
            "[ 0.98932068 11.68305443  0.99438859  0.99048681]\n",
            "\n",
            "Accuracy Prediction for Batch Gradient descent Algorithm With Regularization\n",
            "30.277880568027697\n",
            "--------------------------------------------------------------\n",
            " \n",
            "Theta Value for Stochastic Gradient descent Algorihtm With Regularization\n",
            "[ 1.17681973 12.49848237  0.1428034   0.08300879]\n",
            " \n",
            "Accuracy Prediction for Stochastic Gradient descent Algorithm With Regularization\n",
            "29.983626517147133\n",
            "--------------------------------------------------------------\n",
            " \n",
            "Theta Value for Mini Batch Gradient descent Algorihtm With Regularization\n",
            "[0.98250509 6.90047835 0.98483188 0.9828692 ]\n",
            " \n",
            "Accuracy Prediction for Mini Batch Gradient descent Algorithm With Regularization\n",
            "47.51233426715228\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}