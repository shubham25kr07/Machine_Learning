{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F3CimFcz5fz"
      },
      "source": [
        "import numpy as np\n",
        "from csv import DictReader as dr\n",
        "import pandas as pd\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkPoCP7V0tuW"
      },
      "source": [
        "data=pd.read_csv('/heart_data.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PYcqGTY0ndq"
      },
      "source": [
        "def confusion_mat(y_test,y_pred):\n",
        "    lamb=np.zeros([2, 2], dtype = int)\n",
        "    for i in range(len(y_test)):\n",
        "        if(y_test[i]==1 and y_pred[i]==1):\n",
        "            lamb[0][0]+=1\n",
        "        elif(y_test[i]==1 and y_pred[i]==0):\n",
        "            lamb[1][0]+=1\n",
        "        elif(y_test[i]==0 and y_pred[i]==0):\n",
        "            lamb[1][1]+=1\n",
        "        else:\n",
        "            lamb[0][1]+=1\n",
        "    return lamb\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8czzvxK02Za"
      },
      "source": [
        "def sigmoid_func(x):\n",
        "    return (1/(1+np.exp(-x)))\n",
        "\n",
        "def computeError(predicted, actual):\n",
        "    err = np.mean(predicted != actual)\n",
        "    return err * 100"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecg2tV5M06MH"
      },
      "source": [
        "def find_y(Y):\n",
        "    m=len(Y)\n",
        "    for i in range(m):\n",
        "       # print(Y[i])\n",
        "        if Y[i]>=0.5:\n",
        "            Y[i]=1\n",
        "        else:\n",
        "            Y[i]=0\n",
        "    return Y\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yZoEILs08d7"
      },
      "source": [
        "def denormalise_price(price):\n",
        "    global mean\n",
        "    global stddev\n",
        "    #print(price)\n",
        "    ret = price * stddev[13] + mean[13]\n",
        "    #print()\n",
        "    #print(ret)\n",
        "    return ret\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8orWnf0-OT"
      },
      "source": [
        "def batch_gradient(X_train,Y_train):\n",
        "    interations=1000\n",
        "    alpha = 0.01        \n",
        "    W0 = 0\n",
        "    W1 = 0\n",
        "    sz = len(X_train)\n",
        "            \n",
        "    costs = []\n",
        "    W = [[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]\n",
        "    W=np.array(W)\n",
        "    lamda=0.01 *(np.ones(W.shape))\n",
        "    #print(X_train.shape)\n",
        "    for epoc in range(interations):\n",
        "        s=sigmoid_func(X_train.dot(W))\n",
        "       # print(s.shape,Y_train.shape)\n",
        "        d=(s-Y_train)\n",
        "       # print(d.shape)\n",
        "        #print(d.shape)\n",
        "        diff=X_train.T.dot(d)*(alpha/sz)\n",
        "       # print(diff.shape)\n",
        "        W = W*(1-alpha*lamda/sz) - diff\n",
        "        new_Cost = np.sum((sigmoid_func(X_train.dot(W))-Y_train)**2)/(2*sz)\n",
        "        costs.append(new_Cost)\n",
        "    return (costs,W)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0TyaqK0ydu"
      },
      "source": [
        "\n",
        "mean = data.mean()\n",
        "stddev = data.std()\n",
        "\n",
        "data = (data - data.mean())/data.std()\n",
        "\n",
        "X=data.iloc[:,:-1]\n",
        "Y=data.iloc[:,-1:]\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "one = np.ones((len(X),1))\n",
        "X = np.concatenate((one,X),axis=1)\n",
        "totalsize = len(X)\n",
        "trainsize = int(totalsize*0.7)\n",
        "\n",
        "X_train = X[:trainsize]\n",
        "X_test = X[trainsize:]\n",
        "Y_train = Y[:trainsize]\n",
        "Y_test = Y[trainsize:]\n",
        "costs,W=batch_gradient(X_train,Y_train)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDXmh01X1Jlv",
        "outputId": "02505345-a58a-4c2c-bb0b-8f2f25d43d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"Batch_Gradient Feature Scaling \")\n",
        "# print(\"Parameters:\\n\",W)\n",
        "print()\n",
        "\n",
        "Y_pred=sigmoid_func(np.dot(X_test,W))\n",
        "Y_pred=denormalise_price(Y_pred)\n",
        "\n",
        "Y_pred=find_y(Y_pred)\n",
        "\n",
        "er=computeError(Y_pred,denormalise_price(Y_test))\n",
        "print(\"Error:\",er,\"%\\nAccuracy:\",100-er,\"%\")\n",
        "print(\"----------------------------\\n\")\n",
        "conf=confusion_mat(denormalise_price(Y_test),Y_pred)\n",
        "acc=(conf[0][0]+conf[1][1])/(conf[0][0]+conf[0][1]+conf[1][0]+conf[1][1])\n",
        "\n",
        "print(\"According to Confusion matrix:\")\n",
        "print(\"\")\n",
        "print(\"Accuracy:\",acc*100)\n",
        "\n",
        "recall=conf[0][0]/(conf[1][0]+conf[0][0])\n",
        "\n",
        "print(\"Recall:\",recall*100)\n",
        "pre=conf[0][0]/(conf[0][1]+conf[0][0])\n",
        "\n",
        "print(\"Precision:\",pre*100)\n",
        "tnr=conf[1][1]/(conf[0][1]+conf[1][1])\n",
        "\n",
        "print(\"True Negative rate:\",tnr*100)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch_Gradient Feature Scaling \n",
            "\n",
            "Error: 19.78021978021978 %\n",
            "Accuracy: 80.21978021978022 %\n",
            "----------------------------\n",
            "\n",
            "According to Confusion matrix:\n",
            "\n",
            "Accuracy: 80.21978021978022\n",
            "Recall: 69.76744186046511\n",
            "Precision: 85.71428571428571\n",
            "True Negative rate: 89.58333333333334\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}