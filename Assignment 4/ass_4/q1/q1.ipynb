{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "iit2018146_q1.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdEGr14vj4Ne"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlnCGRBpj4No"
      },
      "source": [
        "dataset = pd.read_csv('results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amJNm1goj4Ns",
        "outputId": "c28aa720-2787-4d84-834e-67ad13bfa217"
      },
      "source": [
        "print(dataset.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       exam1      exam2  admission\n",
            "0  34.623660  78.024693          0\n",
            "1  30.286711  43.894998          0\n",
            "2  35.847409  72.902198          0\n",
            "3  60.182599  86.308552          1\n",
            "4  79.032736  75.344376          1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKOTGgYfj4PI"
      },
      "source": [
        "shuffled_dataset = dataset.sample(frac=1)\n",
        "X = dataset.iloc[:,:-1]\n",
        "Y = dataset.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PxswfLgj4PO"
      },
      "source": [
        "def split_data(fraction_size, dataset):\n",
        "    train_size = int(fraction_size*dataset.shape[0])\n",
        "    train = dataset.iloc[:train_size,:]\n",
        "    test  = dataset.iloc[train_size:,:]\n",
        "    X_test = test.iloc[:,:-1].values\n",
        "    Y_test = test.iloc[:,-1].values\n",
        "    return train, test, X_test,Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad24CWI5j4PU"
      },
      "source": [
        "def gradient_batch(X,Y,L=0.001):\n",
        "    m = np.zeros(shape=(1,X.shape[1]))\n",
        "    c = 0\n",
        "    epochs = 2000\n",
        "    theta0=[]\n",
        "    theta1=[]\n",
        "    cost = []\n",
        "    # epochs value choose inversely proportional to L\n",
        "    n = float(len(Y))\n",
        "    sample = X.shape[0]\n",
        "    for iter in range(epochs):\n",
        "        temp_m=  np.zeros(shape=(1,X.shape[1]))\n",
        "        temp_c = 0\n",
        "        for i in range(len(Y)):\n",
        "            Y_pred = np.dot(m,X[i])+c\n",
        "            temp_m =  X[i]*((Y[i]- Y_pred))\n",
        "            temp_c =  (Y[i]- Y_pred)\n",
        "        m = m - L*(-2/sample)*temp_m\n",
        "        c = c - L*(-2/sample)*temp_c\n",
        "    return m,c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiRv9_Zkj4PZ"
      },
      "source": [
        "def predict(X,m,c):\n",
        "    y = []\n",
        "    for i in range(len(X)):\n",
        "        prediction = np.dot(m,X[i])+c\n",
        "        y.append(prediction)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFV9Mw1Jj4Ph"
      },
      "source": [
        "def calc_MAE(Y_predict, Y):\n",
        "    mae = 0\n",
        "    n = len(Y)\n",
        "    for i in range (n):\n",
        "        mae += abs((Y_predict[i]-Y[i]))\n",
        "    mae = (mae*100)/n\n",
        "    return mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb86w9-Dj4Po"
      },
      "source": [
        "# Batch GD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhWHAWvKj4Pp"
      },
      "source": [
        "def batch_GD(train_data,learning_rate,decL, epoch):\n",
        "    w=np.ones(shape=(1,train_data.shape[1]-1))\n",
        "    b=0\n",
        "    cur_iter=1\n",
        "    while(cur_iter<=epoch): \n",
        "        temp=train_data\n",
        "        y=np.array(temp['admission'])\n",
        "        x=np.array(temp.drop('admission',axis=1))\n",
        "        w_gradient=np.zeros(shape=(1,train_data.shape[1]-1))\n",
        "        b_gradient=0\n",
        "        n = train_data.shape[0]\n",
        "        for i in range(n):\n",
        "            prediction=np.dot(w,x[i])+b\n",
        "            w_gradient=w_gradient+(2)*x[i]*(y[i]-(prediction))\n",
        "            b_gradient=b_gradient+(2)*(y[i]-(prediction))\n",
        "        w=w-learning_rate*(w_gradient/n)\n",
        "        b=b-learning_rate*(b_gradient/n)\n",
        "        \n",
        "        cur_iter=cur_iter+1\n",
        "#         learning_rate=learning_rate/decL\n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV109icNj4Pt"
      },
      "source": [
        "# Stochastic GD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGypqkubj4Pu"
      },
      "source": [
        "def stochastic_GD(train_data,learning_rate,decL, epoch):\n",
        "    w=np.zeros(shape=(1,train_data.shape[1]-1))\n",
        "    b=0\n",
        "    cur_iter=1\n",
        "    while(cur_iter<=epoch): \n",
        "        temp=train_data\n",
        "        y=np.array(temp['admission'])\n",
        "        x=np.array(temp.drop('admission',axis=1))\n",
        "        w_gradient=np.zeros(shape=(1,train_data.shape[1]-1))\n",
        "        b_gradient=0\n",
        "        i = cur_iter % len(y)\n",
        "        prediction=np.dot(w,x[i])+b\n",
        "        w_gradient=w_gradient+(-2)*x[i]*(y[i]-(prediction))\n",
        "        b_gradient=b_gradient+(-2)*(y[i]-(prediction))\n",
        "        w=w-learning_rate*(w_gradient)\n",
        "        b=b-learning_rate*(b_gradient)\n",
        "        \n",
        "        cur_iter=cur_iter+1\n",
        "#         learning_rate=learning_rate/decL\n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7yszYej4Px"
      },
      "source": [
        "# Mini Batch GD \n",
        "### default size = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro4ztmWgj4Py"
      },
      "source": [
        "def miniBatch_GD(train_data,learning_rate,k,decL, epoch):\n",
        "    w=np.zeros(shape=(1,train_data.shape[1]-1))\n",
        "    b=0\n",
        "    cur_iter=1\n",
        "    start = -k\n",
        "    while(cur_iter<=epoch): \n",
        "        temp=train_data\n",
        "        \n",
        "        y=np.array(temp['admission'])\n",
        "        x=np.array(temp.drop('admission',axis=1))\n",
        "        w_gradient=np.zeros(shape=(1,train_data.shape[1]-1))\n",
        "        b_gradient=0\n",
        "        start = (start + k) %len(y)\n",
        "        for i in range(start, start + k):\n",
        "            i = i % len(y)\n",
        "            prediction=np.dot(w,x[i])+b\n",
        "            w_gradient=learning_rate*w_gradient+(-2)*learning_rate*x[i]*(y[i]-(prediction))\n",
        "            b_gradient=learning_rate*b_gradient+(-2)*learning_rate*(y[i]-(prediction))\n",
        "        w=w-(w_gradient/k)\n",
        "        b=b-(b_gradient/k)\n",
        "        cur_iter=cur_iter+1\n",
        "#         learning_rate=learning_rate/decL\n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77wQwRX8j4P1"
      },
      "source": [
        "# Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZUe98Zfj4P2"
      },
      "source": [
        "train, test, X_test, Y_test = split_data(0.7, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvE6If5j4P5"
      },
      "source": [
        "\n",
        "\n",
        "# Without Feature Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V__vkKNuj4P6",
        "outputId": "9d9be747-a20f-482f-9b0a-110259be7166"
      },
      "source": [
        "y  = train.iloc[:,1].values\n",
        "tr = train\n",
        "tr = tr.drop('admission',axis=1)\n",
        "x  = tr.values \n",
        "m1,c1 = gradient_batch(x,y,L=0.01)\n",
        "Y_predict = predict(X_test,m1[0],c1[0])\n",
        "\n",
        "for i in range(len(Y_predict)):\n",
        "    if(Y_predict[i] > 0.5):\n",
        "        Y_predict[i] = 1\n",
        "    else:\n",
        "        Y_predict[i] = 0\n",
        "# for i in range(len(X_test)):\n",
        "#     print(Y_test[i], Y_predict[i])\n",
        "mae1 = calc_MAE(Y_predict, Y_test)\n",
        "print(\"Mean Absolute Error in Test  Data = {} %\".format(mae1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error in Test  Data = 80.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-mZchE_j4P-",
        "outputId": "1aaa41ef-af16-4d4f-db13-1ca3344db81f"
      },
      "source": [
        "m2,c2 = stochastic_GD(train.iloc[:,:], 0.00001, 2, 3000)\n",
        "Y_predict2 = predict(X_test,m2[0],c2[0])\n",
        "# print(m2,c2)\n",
        "\n",
        "for i in range(len(Y_predict2)):\n",
        "    if(Y_predict2[i] > 0.5):\n",
        "        Y_predict2[i] = 1\n",
        "    else:\n",
        "        Y_predict2[i] = 0\n",
        "# for i in range(len(X_test)):\n",
        "#     print(Y_test[i], Y_predict2[i])\n",
        "mae2 = calc_MAE(Y_predict2, Y_test)\n",
        "print(\"Mean Absolute Error in Test  Data = {} %\".format(mae2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error in Test  Data = 16.666666666666668 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4SDudHHj4QB",
        "outputId": "48760270-f181-4adb-c69e-c253b422f757"
      },
      "source": [
        "m3,c3 = miniBatch_GD(train.iloc[:,:], 0.0000001,  30, 2, 2000)\n",
        "Y_predict3 = predict(X_test,m3[0],c3[0])\n",
        "\n",
        "for i in range(len(Y_predict3)):\n",
        "    if(Y_predict3[i] > 0.5):\n",
        "        Y_predict3[i] = 1\n",
        "    else:\n",
        "        Y_predict3[i] = 0\n",
        "\n",
        "mae3 = calc_MAE(Y_predict3, Y_test)\n",
        "print(\"Mean Absolute Error in Test  Data = {} %\".format(mae3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error in Test  Data = 80.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5jhU0DDj4QI"
      },
      "source": [
        "# Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw7RVM3Nj4QI"
      },
      "source": [
        "def standardize(data, col):\n",
        "    temp = np.array(data[col])\n",
        "    sd = np.std(temp)\n",
        "    mean = np.mean(temp)\n",
        "    temp = (temp - mean) / sd\n",
        "    data[col] = temp\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHrzeMp_j4QL"
      },
      "source": [
        "# dataset = standardize(dataset,'exam2')\n",
        "dataset = standardize(dataset,'exam1')\n",
        "train, test, X_test, Y_test = split_data(0.7, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IH57Psej4QO",
        "outputId": "a9371afb-76e5-44a8-8121-bb25293d1d03"
      },
      "source": [
        "y  = train.iloc[:,1].values\n",
        "tr = train\n",
        "tr = tr.drop('admission',axis=1)\n",
        "x  = tr.values \n",
        "m21,c21 = gradient_batch(x,y,L=0.00000004)\n",
        "Y_predict21 = predict(X_test,m21[0],c21[0])\n",
        "# print(tr)\n",
        "# for i in range(len(X_test)):\n",
        "#     print(Y_test[i], Y_predict21[i])\n",
        "for i in range(len(Y_predict21)):\n",
        "    if(Y_predict21[i] > 0.5):\n",
        "        Y_predict21[i] = 1\n",
        "    else:\n",
        "        Y_predict21[i] = 0\n",
        "  \n",
        "mae21 = calc_MAE(Y_predict21, Y_test)\n",
        "\n",
        "print(\"Mean Absolute Error in Test  Data = {} %\".format(mae21))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error in Test  Data = 16.666666666666668 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WfV_xPmj4QS",
        "outputId": "b7cd13c7-f22a-461c-bc93-a0e5f6acd48e"
      },
      "source": [
        "m22,c22 = stochastic_GD(train.iloc[:,:], 0.0001, 2, 5000)\n",
        "Y_predict22 = predict(X_test,m22[0],c22[0])\n",
        "for i in range(len(Y_predict22)):\n",
        "    if(Y_predict22[i] > 0.5):\n",
        "        Y_predict22[i] = 1\n",
        "    else:\n",
        "        Y_predict22[i] = 0\n",
        "mae22 = calc_MAE(Y_predict22, Y_test)\n",
        "print(\"Mean Absolute Error in Test  Data = {} %\".format(mae22))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error in Test  Data = 13.333333333333334 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhgRkxUlj4QV",
        "outputId": "d4570623-f8ef-41de-cd32-3271554a886c"
      },
      "source": [
        "m23,c23 = miniBatch_GD(train.iloc[:,:], 0.000001,  20, 2, 5000)\n",
        "Y_predict23 = predict(X_test,m23[0],c23[0])\n",
        "for i in range(len(Y_predict21)):\n",
        "    if(Y_predict23[i] > 0.5):\n",
        "        Y_predict23[i] = 1\n",
        "    else:\n",
        "        Y_predict23[i] = 0\n",
        "mae23 = calc_MAE(Y_predict23, Y_test)\n",
        "print(\"Mean Absolute Error in Test  Data = {} %\".format(mae23))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error in Test  Data = 16.666666666666668 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa0n1OfJj4Qb"
      },
      "source": [
        "# Compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpBu9731j4Qc",
        "outputId": "e9209f85-3670-461a-f96a-c41eac7eee93"
      },
      "source": [
        "print(\"Without Feature Scaling-----\")\n",
        "print(\"===========================================\")\n",
        "print(\"Batch GD: MAEP      = {} %\".format(mae1))\n",
        "print(\"Stochastic GD: MAEP = {} %\".format(mae2))\n",
        "print(\"Mini-Batch GD: MAEP = {} %\".format(mae3))\n",
        "print()\n",
        "print(\"Feature Scaling using standardization------\")\n",
        "print(\"===========================================\")\n",
        "print(\"Batch GD: MAEP      = {} %\".format(mae21))\n",
        "print(\"Stochastic GD: MAEP = {} %\".format(mae22))\n",
        "print(\"Mini-Batch GD: MAEP = {} %\".format(mae23))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Feature Scaling-----\n",
            "===========================================\n",
            "Batch GD: MAEP      = 80.0 %\n",
            "Stochastic GD: MAEP = 16.666666666666668 %\n",
            "Mini-Batch GD: MAEP = 80.0 %\n",
            "\n",
            "Feature Scaling using standardization------\n",
            "===========================================\n",
            "Batch GD: MAEP      = 16.666666666666668 %\n",
            "Stochastic GD: MAEP = 13.333333333333334 %\n",
            "Mini-Batch GD: MAEP = 16.666666666666668 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}