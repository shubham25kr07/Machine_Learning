{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "iit2018146_ml.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "djBmGSLbQI5L"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pda\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "import re\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm9A7RLeQI5d"
      },
      "source": [
        "Msg = pda.read_csv('/SMSSpamCollection',sep = '\\t', header = None, names=['spam/ham','SMS'])"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqrkWctGjKh8"
      },
      "source": [
        "def Training_Test_set(Msg):\n",
        "  train_set,test_set = tts(Msg,test_size = 0.2, random_state = 60)\n",
        "  train_set['SMS'] = train_set['SMS'].str.replace('\\W', ' ')\n",
        "  train_set['SMS'] = train_set['SMS'].str.lower()\n",
        "  test_set['SMS'] = test_set['SMS'].str.replace('\\W', ' ')\n",
        "  test_set['SMS'] = test_set['SMS'].str.lower()\n",
        "  return test_set,train_set"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hS-mnUhRQI50"
      },
      "source": [
        "test,train=Training_Test_set(Msg)"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-HztWkeU_0d"
      },
      "source": [
        "def make_words(train):\n",
        "  vocabulary = []\n",
        "  for msg in train['SMS']:\n",
        "      for word in msg:\n",
        "          vocabulary.append(word)\n",
        "  vocabulary = list(set(vocabulary))\n",
        "  return vocabulary"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6hNyYjmQI6F"
      },
      "source": [
        "train['SMS'] = train['SMS'].str.split()\n",
        "vocabulary=make_words(train)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro0f0Je7QI6I"
      },
      "source": [
        "wcp_msg = {uniqueWord: [0]*len(train['SMS']) for uniqueWord in vocabulary}\n",
        "for idx, msg in enumerate(train['SMS']):\n",
        "    for word in msg:\n",
        "        wcp_msg[word][idx] +=1\n",
        "wc = pda.DataFrame(wcp_msg)"
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlIeva1KQI6O"
      },
      "source": [
        "final_train = pda.concat([train,wc],axis = 1)"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqE431VmlXiO"
      },
      "source": [
        "# MULTINOMIAL NAIVE BAYES CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag49G3zhQI6W"
      },
      "source": [
        "spamMsgs = final_train[final_train['spam/ham']=='spam']\n",
        "hamMsgs = final_train[final_train['spam/ham']=='ham']"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDTRdgNpQI6Z"
      },
      "source": [
        "pSpam = len(spamMsgs)/len(final_train)\n",
        "# print(pSpam)\n",
        "pHam = len(hamMsgs)/len(final_train)"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut1gewYBQI6b"
      },
      "source": [
        "noOfWordsPerSpamMsgs = spamMsgs['SMS'].apply(len)\n",
        "noSpam = noOfWordsPerSpamMsgs.sum()\n",
        "noOfWordsPerHamMsgs = hamMsgs['SMS'].apply(len)\n",
        "noHam = noOfWordsPerHamMsgs.sum()\n",
        "noOfvocabulary = len(vocabulary)\n",
        "alpha = 1"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPh6LgSqQI6e"
      },
      "source": [
        "paramSpam = {uniqueWord: 0 for uniqueWord in vocabulary}\n",
        "paramHam = {uniqueWord: 0 for uniqueWord in vocabulary}"
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwCYxxNFQI6h"
      },
      "source": [
        "for word in vocabulary:\n",
        "    noOfWordsGivenSpam = spamMsgs[word].sum()\n",
        "    probOfWordsGivenSpam = (noOfWordsGivenSpam + alpha)/(noSpam + alpha*noOfvocabulary)\n",
        "    paramSpam[word] = probOfWordsGivenSpam\n",
        "    noOfWordsGivenHam = hamMsgs[word].sum()\n",
        "    probOfWordsGivenHam = (noOfWordsGivenHam + alpha)/(noHam + alpha*noOfvocabulary)\n",
        "    paramHam[word] = probOfWordsGivenHam"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrINk6PoQI6k"
      },
      "source": [
        "def classifytest(msg):\n",
        "    msg = re.sub('\\W', ' ', msg)\n",
        "    msg = msg.lower().split()\n",
        "    \n",
        "    probOfSpamGivenMsg = pSpam\n",
        "    probOfHamGivenMsg = pHam\n",
        "    \n",
        "    for word in msg:\n",
        "        if word in paramSpam:\n",
        "            probOfSpamGivenMsg *= paramSpam[word]\n",
        "            \n",
        "        if word in paramHam:\n",
        "            probOfHamGivenMsg *= paramHam[word]\n",
        "            \n",
        "        if probOfSpamGivenMsg > probOfHamGivenMsg:\n",
        "            return 'spam'\n",
        "        elif probOfHamGivenMsg > probOfSpamGivenMsg:\n",
        "            return 'ham'\n",
        "        else:\n",
        "            return 'need human classification'"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOl5vu8VQI6n"
      },
      "source": [
        "test['pred'] = test['SMS'].apply(classifytest)"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xkjLDw9QI6q",
        "outputId": "86d9dded-b143-4b7c-82d0-8a8e531d8110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "right = 0\n",
        "tot = test.shape[0]\n",
        "\n",
        "for row in test.iterrows():\n",
        "    row = row[1]\n",
        "    if(row['spam/ham']==row['pred']):\n",
        "        right +=1\n",
        "        \n",
        "print('Correct: ', right)\n",
        "print('Wrong: ',tot-right)\n",
        "print('Accuracy: ',right/tot)\n",
        "print('Error: ', 1 -(right/tot))"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Right:  959\n",
            "Wrong:  156\n",
            "Accuracy:  0.8600896860986547\n",
            "Error:  0.13991031390134534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG-Rcq9En5jN"
      },
      "source": [
        "# Gaussian Discriminant Analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyPKtdp2QI6w"
      },
      "source": [
        "trainingY = final_train['spam/ham'].copy()\n",
        "trainingX = final_train[final_train.columns[2:]]"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxm7qURbQI6z"
      },
      "source": [
        "trainingY = trainingY.to_numpy()\n",
        "trainingX = trainingX.to_numpy()"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUIjqNWCQI62"
      },
      "source": [
        "X_one = []\n",
        "X_zero = []\n",
        "\n",
        "for i in range(len(trainingY)):\n",
        "    if trainingY[i] == 'spam':\n",
        "        X_one.append(trainingX[i])\n",
        "    elif trainingY[i] == 'ham':\n",
        "        X_zero.append(trainingX[i])"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w557n2iQI65",
        "outputId": "c6cca0ae-4f74-4bc4-9ea2-76b516386418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "phi = float(len(X_one)/(len(X_one)+len(X_zero)))\n",
        "mu0 = np.sum(np.matrix(X_zero),axis = 0)/len(X_zero)\n",
        "mu1 = np.sum(np.matrix(X_one),axis = 0)/len(X_one)\n",
        "print(\"Phi = \", phi)\n",
        "print(\"mu0 = \", mu0)\n",
        "print(\"mu1 = \", mu1)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Phi =  0.13260040385909805\n",
            "mu0 =  [[nan nan nan ... nan nan nan]]\n",
            "mu1 =  [[nan nan nan ... nan nan nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caKkgDVdQI6_"
      },
      "source": [
        "sigma = np.zeros((trainingX.shape[1],trainingX.shape[1]))\n",
        "sigma0 = np.zeros((trainingX.shape[1],trainingX.shape[1]))\n",
        "sigma1 = np.zeros((trainingX.shape[1],trainingX.shape[1]))\n"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPXMVUr2QI7C"
      },
      "source": [
        "for i in range(len(trainingX)):\n",
        "   if(trainingY[i] == 'spam'):\n",
        "       sigma1 += np.dot(np.transpose(trainingX[i]-mu1),trainingX[i]-mu1)\n",
        "   elif trainingY[i]=='ham':\n",
        "       sigma0 += np.dot(np.transpose(trainingX[i]-mu0),trainingX[i]-mu0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teOxjYikQI7F"
      },
      "source": [
        "sigma = (sigma1 + sigma0)/(len(X_one)+len(X_zero))\n",
        "sigma0 /= len(X_one)\n",
        "sigma1 /= len(X_zero)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFzpIGAqQI7H"
      },
      "source": [
        "def probFunction(x,mu,sigma):\n",
        "   m = len(x)\n",
        "   if m == mu.shape[1] and (m,m) == sigma.shape:\n",
        "       deter = np.linalg.det(sigma)\n",
        "       assert deter!=0, \"matrix cannot be singular\"\n",
        "        \n",
        "       temp = 1.0/(np.power((2*np.pi),float(m)/2)*np.power(deter,1.0/2))\n",
        "       xmu = np.matrix(x-mu)\n",
        "       siginv = inv(sigma)\n",
        "       res = np.power(np.e,-0.5*(np.dot(np.dot(xmu,siginv),np.transpose(xmu))))\n",
        "       return res*temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xGEChMgQI7K"
      },
      "source": [
        "test['SMS'] = test['SMS'].str.split()\n",
        "\n",
        "vocabulary = []\n",
        "for msg in test['SMS']:\n",
        "    for word in msg:\n",
        "        vocabulary.append(word)\n",
        "        \n",
        "vocabulary = list(set(vocabulary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGJsEQHBQI7N"
      },
      "source": [
        "wcp_msg = {uniqueWord: [0]*len(test['SMS']) for uniqueWord in vocabulary}\n",
        "\n",
        "for idx, msg in enumerate(test['SMS']):\n",
        "    for word in msg:\n",
        "        wcp_msg[word][idx] +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GYNa9ZwQI7P"
      },
      "source": [
        "wc = pda.DataFrame(wcp_msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "285Nt_FDQI7S"
      },
      "source": [
        "testFinal = pda.concat([test,wc],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBPHQB1sQI7V"
      },
      "source": [
        "testingY = testFinal['spam/ham'].copy()\n",
        "testingX = testFinal[testFinal.columns[2:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nzejZOMQI7X"
      },
      "source": [
        "testingY = testingY.to_numpy()\n",
        "testingX = testingX.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBQTmV4SQI7a"
      },
      "source": [
        "predictedY = []\n",
        "for x in testingX:\n",
        "   pa = probFunction(x,np.squeeze(mu0),np.matrix(sigma0))\n",
        "   pc = probFunction(x,np.squeeze(mu1),np.matrix(sigma1))\n",
        "   if (pa<pc):\n",
        "       predictedY.append('spam')\n",
        "   else:\n",
        "       predictedY.append('ham')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ul6FF1NQI7d"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(testingY)):\n",
        "   if(predictedY[i]==testingY[i]):\n",
        "       count = count + 1\n",
        "        \n",
        "accuracy = np.multiply(np.divide(count,len(testingY)),100)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}